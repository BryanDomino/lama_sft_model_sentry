{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a39c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_model import MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c57dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types import DataType, Schema, ColSpec, ParamSchema, ParamSpec\n",
    "\n",
    "# Define input and output schema\n",
    "input_schema = Schema(\n",
    "    [\n",
    "        ColSpec(DataType.string, \"prompt\"),\n",
    "    ]\n",
    ")\n",
    "output_schema = Schema([ColSpec(DataType.string, \"text_from_llm\")])\n",
    "\n",
    "parameters = ParamSchema(\n",
    "    [       \n",
    "    ]\n",
    ")\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema, params=parameters)\n",
    "\n",
    "\n",
    "# Define input example\n",
    "input_example = pd.DataFrame({\"prompt\": [\"What is machine learning?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0254a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf /tmp/mlflow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Release CUDA memory\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import transformers\n",
    "import peft\n",
    "import trl\n",
    "import torch\n",
    "import transformers\n",
    "# Save the model\n",
    "mlflow.pyfunc.save_model(path=\"/tmp/mlflow/\", python_model=MyModel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe63118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for inference\n",
    "model = mlflow.pyfunc.load_model(\"/tmp/mlflow/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2dcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict({\"prompt\" : \"Where is Cancun?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bfdbea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
